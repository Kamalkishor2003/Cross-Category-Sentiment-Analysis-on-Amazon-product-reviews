{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzdv8uk0OjBqTgQGgzwrj0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3IojpRCUf6p","executionInfo":{"status":"ok","timestamp":1760539439768,"user_tz":-330,"elapsed":10470,"user":{"displayName":"KAMALKISHOR SURESHKUMAR SUNWASIYA","userId":"17096036952901544385"}},"outputId":"3d704c47-c6ac-4dac-bc1a-b2992ca37aad"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Colab cell (bash)\n","!pip install -q streamlit scikit-learn sentence-transformers pyngrok joblib matplotlib seaborn scipy\n"]},{"cell_type":"code","source":["%%bash\n","cat > streamlit_app.py <<'PY'\n","# streamlit_app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","from sentence_transformers import SentenceTransformer\n","from scipy.sparse import hstack, csr_matrix\n","\n","st.set_page_config(page_title=\"Hybrid Sentiment Demo\", layout=\"wide\")\n","sns.set_style(\"whitegrid\")\n","\n","# ---- User inputs (change paths here if needed) ----\n","ELEC_PATH = \"/content/Amazon_Reviews_Filtered.csv\"   # training CSV (Electronics)\n","BOOKS_PATH = \"/content/filtered_reviews.csv\"         # testing CSV (Books)\n","TFIDF_MAX_FEATURES = 5000\n","# ----------------------------------------------------\n","\n","@st.cache_data(show_spinner=False)\n","def load_data(elec_path, books_path):\n","    df_e = pd.read_csv(elec_path)\n","    df_b = pd.read_csv(books_path)\n","    return df_e, df_b\n","\n","@st.cache_resource(show_spinner=False)\n","def prepare_models(train_df, test_df, text_col_train='reviewText', text_col_test='reviewText', max_tfidf=5000):\n","    # Prepare labels (drop neutral = 3)\n","    train = train_df[[text_col_train, 'overall']].dropna().copy()\n","    test = test_df[[text_col_test, 'overall']].dropna().copy()\n","    train[text_col_train] = train[text_col_train].astype(str)\n","    test[text_col_test] = test[text_col_test].astype(str)\n","\n","    def to_label(x):\n","        try:\n","            xv = float(x)\n","        except:\n","            return np.nan\n","        if xv <= 2.0:\n","            return 0\n","        elif xv >= 4.0:\n","            return 1\n","        else:\n","            return np.nan\n","\n","    train['label'] = train['overall'].apply(to_label)\n","    test['label'] = test['overall'].apply(to_label)\n","    train = train.dropna(subset=['label'])\n","    test = test.dropna(subset=['label'])\n","    train['label'] = train['label'].astype(int)\n","    test['label'] = test['label'].astype(int)\n","\n","    X_train_texts = train[text_col_train].values\n","    y_train = train['label'].values\n","    X_test_texts = test[text_col_test].values\n","    y_test = test['label'].values\n","\n","    # TF-IDF\n","    vectorizer = TfidfVectorizer(stop_words='english', max_features=max_tfidf)\n","    X_train_tfidf = vectorizer.fit_transform(X_train_texts)\n","    X_test_tfidf = vectorizer.transform(X_test_texts)\n","\n","    # SBERT (embedding)\n","    sbert = SentenceTransformer('all-MiniLM-L6-v2')\n","    X_train_bert = sbert.encode(list(X_train_texts), convert_to_numpy=True, show_progress_bar=False)\n","    X_test_bert = sbert.encode(list(X_test_texts), convert_to_numpy=True, show_progress_bar=False)\n","\n","    # Hybrid\n","    X_train_hybrid = hstack([X_train_tfidf, csr_matrix(X_train_bert)])\n","    X_test_hybrid = hstack([X_test_tfidf, csr_matrix(X_test_bert)])\n","\n","    # Models\n","    nb = MultinomialNB()\n","    lr = LogisticRegression(max_iter=2000)\n","    svm = LinearSVC()\n","    rf = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n","\n","    # Train\n","    nb.fit(X_train_tfidf, y_train)               # NB uses TF-IDF only\n","    lr.fit(X_train_hybrid, y_train)\n","    svm.fit(X_train_hybrid, y_train)\n","    rf.fit(X_train_hybrid, y_train)\n","\n","    # Predict on test\n","    preds = {}\n","    preds['Naive Bayes'] = nb.predict(X_test_tfidf)\n","    preds['Logistic Regression'] = lr.predict(X_test_hybrid)\n","    preds['SVM'] = svm.predict(X_test_hybrid)\n","    preds['Random Forest'] = rf.predict(X_test_hybrid)\n","\n","    # Metrics\n","    results = {}\n","    for name, y_pred in preds.items():\n","        acc = accuracy_score(y_test, y_pred)\n","        prec = precision_score(y_test, y_pred, zero_division=0)\n","        rec = recall_score(y_test, y_pred, zero_division=0)\n","        f1 = f1_score(y_test, y_pred, zero_division=0)\n","        results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"y_pred\": y_pred}\n","\n","    artifacts = {\n","        \"vectorizer\": vectorizer,\n","        \"sbert\": sbert,\n","        \"nb\": nb,\n","        \"lr\": lr,\n","        \"svm\": svm,\n","        \"rf\": rf,\n","        \"X_test_tfidf\": X_test_tfidf,\n","        \"X_test_hybrid\": X_test_hybrid,\n","        \"y_test\": y_test,\n","        \"results\": results\n","    }\n","    return artifacts\n","\n","# --- UI ---\n","st.title(\"üì¶ Cross-Category Sentiment Demo ‚Äî TF-IDF + SBERT (Hybrid)\")\n","st.write(\"Train on Electronics (train CSV) and test on Books (test CSV).\")\n","\n","with st.spinner(\"Loading data...\"):\n","    try:\n","        df_elec, df_books = load_data(ELEC_PATH, BOOKS_PATH)\n","    except Exception as e:\n","        st.error(f\"Could not load CSV files. Error: {e}\")\n","        st.stop()\n","\n","st.markdown(\"### Dataset samples\")\n","col1, col2 = st.columns(2)\n","with col1:\n","    st.write(\"Electronics (train) sample\")\n","    st.dataframe(df_elec.head(5))\n","with col2:\n","    st.write(\"Books (test) sample\")\n","    st.dataframe(df_books.head(5))\n","\n","with st.spinner(\"Training models and building artifacts (may take 1-2 minutes)...\"):\n","    artifacts = prepare_models(df_elec, df_books, 'reviewText', 'reviewText', TFIDF_MAX_FEATURES)\n","\n","vectorizer = artifacts[\"vectorizer\"]\n","sbert = artifacts[\"sbert\"]\n","nb = artifacts[\"nb\"]\n","lr = artifacts[\"lr\"]\n","svm = artifacts[\"svm\"]\n","rf = artifacts[\"rf\"]\n","y_test = artifacts[\"y_test\"]\n","results = artifacts[\"results\"]\n","\n","st.subheader(\"Model comparison (tested on Books)\")\n","metrics_df = pd.DataFrame([\n","    {\"Model\": m, \"Accuracy\": r[\"accuracy\"], \"Precision\": r[\"precision\"], \"Recall\": r[\"recall\"], \"F1\": r[\"f1\"]}\n","    for m, r in results.items()\n","]).sort_values(\"F1\", ascending=False).reset_index(drop=True)\n","st.dataframe(metrics_df.style.format({\"Accuracy\":\"{:.3f}\", \"Precision\":\"{:.3f}\", \"Recall\":\"{:.3f}\", \"F1\":\"{:.3f}\"}))\n","\n","# --- Attractive comparison plots (F1 & Accuracy) ---\n","sns.set_style(\"whitegrid\")\n","plt.rcParams.update({'font.size': 12})\n","\n","fig, ax = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n","\n","# Left: F1 scores (horizontal, annotated)\n","f1_sorted = metrics_df.sort_values(\"F1\", ascending=True)\n","sns.barplot(x=\"F1\", y=\"Model\", data=f1_sorted, ax=ax[0], palette=\"viridis\")\n","ax[0].set_xlim(0, 1)\n","ax[0].set_xlabel(\"F1 Score\")\n","ax[0].set_title(\"F1 Score (Test)\")\n","for i, (val, name) in enumerate(zip(f1_sorted[\"F1\"].values, f1_sorted[\"Model\"].values)):\n","    ax[0].text(val + 0.01, i, f\"{val:.3f}\", va='center', fontweight='bold', color='black')\n","\n","# Right: Accuracy (horizontal, annotated with different palette)\n","acc_sorted = metrics_df.sort_values(\"Accuracy\", ascending=True)\n","sns.barplot(x=\"Accuracy\", y=\"Model\", data=acc_sorted, ax=ax[1], palette=\"rocket\")\n","ax[1].set_xlim(0, 1)\n","ax[1].set_xlabel(\"Accuracy\")\n","ax[1].set_title(\"Accuracy (Test)\")\n","for i, (val, name) in enumerate(zip(acc_sorted[\"Accuracy\"].values, acc_sorted[\"Model\"].values)):\n","    ax[1].text(val + 0.01, i, f\"{val:.3f}\", va='center', fontweight='bold', color='black')\n","\n","st.pyplot(fig)\n","\n","# Announce best model (by F1)\n","best_model_name = metrics_df.iloc[0][\"Model\"]\n","st.success(f\"Best model (by F1 on Books test): **{best_model_name}**\")\n","\n","# --- Remove confusion matrix display per request (do not show it) ---\n","\n","# ---------------------------\n","# Real-time Prediction Section\n","# ---------------------------\n","st.subheader(\"üß† Real-time Sentiment Prediction\")\n","\n","review = st.text_area(\"Enter a review to predict sentiment:\", height=120)\n","\n","if st.button(\"Predict\"):\n","    if not review.strip():\n","        st.error(\"‚ö†Ô∏è Please enter a review.\")\n","    else:\n","        # Feature extraction\n","        tf_feat = vectorizer.transform([review])\n","        bert_feat = sbert.encode([review], convert_to_numpy=True)\n","        hybrid_feat = hstack([tf_feat, csr_matrix(bert_feat)])\n","\n","        # Predictions from all models\n","        nb_pred = nb.predict(tf_feat)[0]\n","        lr_pred = lr.predict(hybrid_feat)[0]\n","        svm_pred = svm.predict(hybrid_feat)[0]\n","        rf_pred = rf.predict(hybrid_feat)[0]\n","\n","        mapping = {1: \"Positive üòä\", 0: \"Negative üòû\"}\n","\n","        per_model = {\n","            \"Naive Bayes\": mapping[int(nb_pred)],\n","            \"Logistic Regression\": mapping[int(lr_pred)],\n","            \"SVM\": mapping[int(svm_pred)],\n","            \"Random Forest\": mapping[int(rf_pred)],\n","        }\n","\n","        # Show per-model predictions\n","        st.markdown(\"### üìä Model-wise Predictions\")\n","        df_live = pd.DataFrame({\n","            \"Model\": list(per_model.keys()),\n","            \"Prediction\": list(per_model.values()),\n","            \"Accuracy\": [\n","                metrics_df.loc[metrics_df[\"Model\"] == m, \"Accuracy\"].values[0]\n","                for m in per_model.keys()\n","            ]\n","        })\n","\n","        st.table(df_live.style.format({\"Accuracy\": \"{:.3f}\"}))\n","\n","        # üéØ Display only best model prediction\n","        best_model_name = metrics_df.loc[metrics_df[\"F1\"].idxmax(), \"Model\"]\n","        best_pred = df_live.loc[df_live[\"Model\"] == best_model_name, \"Prediction\"].values[0]\n","        best_acc = df_live.loc[df_live[\"Model\"] == best_model_name, \"Accuracy\"].values[0]\n","\n","        st.markdown(\"---\")\n","        st.markdown(f\"### üèÜ Best Model: **{best_model_name}**\")\n","        st.markdown(f\"**Predicted Sentiment:** {best_pred}\")\n","        st.markdown(f\"**Model Accuracy:** `{best_acc:.3f}`\")\n","\n","        # Visualization of accuracies\n","        fig, ax = plt.subplots(figsize=(6, 3))\n","        sns.barplot(x=\"Accuracy\", y=\"Model\", data=df_live, palette=\"coolwarm\", ax=ax)\n","        ax.set_xlim(0, 1)\n","        ax.set_title(\"Model Accuracy on Real-time Review\")\n","        st.pyplot(fig)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Vv4MODBVBnL","executionInfo":{"status":"ok","timestamp":1760547420127,"user_tz":-330,"elapsed":89,"user":{"displayName":"KAMALKISHOR SURESHKUMAR SUNWASIYA","userId":"17096036952901544385"}},"outputId":"57037c57-c313-40c9-97a7-49a35f1eb8a4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["bash: line 253: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n"]}]},{"cell_type":"code","source":["!pip install -q pyngrok\n","from pyngrok import ngrok\n","ngrok.set_auth_token(\"33xQ32F2JBb6URiZ5bHskpcdcbG_81xbFL1TqcVcLy9fzGhS2\")"],"metadata":{"id":"fW_VsK3tVNPE","executionInfo":{"status":"ok","timestamp":1760547177347,"user_tz":-330,"elapsed":5589,"user":{"displayName":"KAMALKISHOR SURESHKUMAR SUNWASIYA","userId":"17096036952901544385"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Start streamlit in background and open ngrok tunnel\n","from pyngrok import ngrok\n","import subprocess, time, os, signal\n","\n","# Kill old tunnels if any\n","ngrok.kill()\n","\n","# Start streamlit app (runs on port 8501 by default)\n","cmd = [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port=8501\", \"--server.headless=true\"]\n","proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","\n","# Wait a few seconds for streamlit to start\n","time.sleep(4)\n","\n","# Open ngrok tunnel to port 8501\n","public_url = ngrok.connect(8501, \"http\")\n","print(\"Streamlit public URL:\", public_url.public_url)\n","print(\"If the page shows a spinner, wait 10-30 seconds and refresh the browser.\")\n","# show the process output tail (optional)\n","time.sleep(1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_dVkewJVR23","executionInfo":{"status":"ok","timestamp":1760547186158,"user_tz":-330,"elapsed":5220,"user":{"displayName":"KAMALKISHOR SURESHKUMAR SUNWASIYA","userId":"17096036952901544385"}},"outputId":"85039934-6bc1-4b99-fd98-17ac362df57d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Streamlit public URL: https://unrecruited-marcelle-lang.ngrok-free.dev\n","If the page shows a spinner, wait 10-30 seconds and refresh the browser.\n"]}]},{"cell_type":"code","source":["# Stop ngrok and kill streamlit\n","from pyngrok import ngrok\n","ngrok.kill()\n","# kill child process (if still running)\n","import psutil, os\n","for p in psutil.process_iter():\n","    if 'streamlit' in ' '.join(p.cmdline()).lower():\n","        p.kill()\n","print(\"Stopped Streamlit and ngrok.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UwOKAQ5WqgI","executionInfo":{"status":"ok","timestamp":1760548509601,"user_tz":-330,"elapsed":30,"user":{"displayName":"KAMALKISHOR SURESHKUMAR SUNWASIYA","userId":"17096036952901544385"}},"outputId":"9d04a10b-f5ba-412b-9d09-a6a2fd1f98a6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Stopped Streamlit and ngrok.\n"]}]}]}